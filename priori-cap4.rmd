---
title: 'La scelta della distribuzione a priori'
output: pdf_document
geometry: left = 2.5cm, right = 2.5cm, top = 2.5cm, bottom = 3cm
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 4.1 Cos'è la distribuzione a priori

L'approccio Bayesiano inizia con la definizione della *distribuzione a priori* , una distribuzione di probabilità che incorpora quello che a priori si pensa in merito al parametro oggetto di studio, prima ancora di raccogliere dati. Scelto un parametro $\pi$ di interesse, il prior ha la funzione di specificare tutti i possibili valori di $\pi$ e la "plausibilità" di ciascuno di essi. Il prior può essere descritto sia da un modello probabilistico discreto che da uno continuo; ad esempio nel primo caso si parla della funzione di probabilità o *Probability mass function* (PMF). In questo modello, data una variabile casuale $X$ discreta, la quantità $p(x)$ esprime la probabilità di verificarsi dell'evento $X=x$. Devono inoltre essere soddisfatte le seguenti proprietà:

-   $p(x)\ge0$;
-   $\sum_{x}p(x)=1$.

Nell' ambito dei modelli continui si ha invece la funzione di densità o *Probability density function*; data una variabile casuale continua $X$ definita nell'intervallo $(l.L)$, la funzione di densità presenta le seguenti proprietà:

-   $f(x)\ge0$;
-   $\int_{l}^{L}f(x)dx=1$;
-   $\int_{a}^{b}f(x)dx=Pr(a\le x\le b)$ $(a>b)$.

Il prior non deve sempre necessariamente incorporare solo quello che si pensa in merito al comportamento del parametro $\pi$ , ma può anche essere costruito a partire da dati già raccolti e che vogliono essere formalizzati in un modello, il prior appunto.

Si considerino i seguenti dati, presi da @BR, Cap.3, che riguardano il consenso registrato in un'elezione politica, in più seggi:



Questi dati possono essere poi presentati nella forma di una distribuzione a priori:

```{r echo=FALSE}
library(bayesrules)
plot_beta(45,55)
```

Sia che si parta da dati già a nostra disposizione, i dati storici, sia che il prior rifletta semplicemente un'idea in merito al comportamento della variabile, ci sono vari modelli a disposizione, ognuno con la propria funzione di probabilità (o di densità). Uno dei più utilizzati è un modello continuo, il modello **Beta**.

# 4.2 La funzione Beta

Data una variabile casuale $\pi$ che può assumere valori da 0 a 1, cioè $\pi \in(0,1)$. Il comportamento della variabile può essere descritto da una funzione Beta, che dipende da due parametri, detti "hyperparameters" in quanto vanno a dettare la forma del prior, $\alpha$ e $\beta$, entambi maggiori di zero.

$\pi \sim Beta(\alpha, \beta)$

Questa funzione ha la seguente funzione di densità:

$f(\pi) =\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\pi^{\alpha-1}(1-\pi)^{\beta-1}$

Usando la beta, questi due parametri sono fondamentali nel costruire la distribuzione a priori in quanto variandoli, la curva assume andamenti molto diversi. Ad esempio dando valore 1 a entrambe i parametri, la Beta prende la forma di un'altro modello, quello della *distribuzione uniforme continua* $\pi \sim Unif(0,1)$

```{r}
library(bayesrules)
plot_beta(1,1)
```

Questa Beta assegna uguale probabilità a tutti valori di $\pi$ da 0 a 1

```{r}
library(bayesrules)
plot_beta(4,7)
plot_beta(1,5)
plot_beta(3,8)
plot_beta(1,1)
plot_beta(6,6)
plot_beta(20,20)
plot_beta(8,3)
plot_beta(5,1)
plot_beta(7,4)
          
```

Da questi esempi di beta si nota una caratteristica dell'andamento del grafico in funzione dei parametri assegnati: 
-se $\alpha$ \> $\beta$ , la curva è più "pesante" a sinistra 
-se $\alpha$ \< $\beta$ la curva è piu "pesante" a destra

Si nota inoltre la grande malleabilità di questa funzione, potendo assegnare minore o maggiore variabilità come si vede nella differenza tra $Beta(6,6)$ e $Beta(20,20)$

Per avere una comprensione ancora maggiore della funzione Beta, e quindi in questo caso della distribuzione a priori, è utile definire le misure di tendenza centrale che sono la Media (o valore atteso) e la Moda. La Media indica il valore medio di $\pi$ , la Moda il valore più plausibile, o, in altre parole, il valore per il quale la funzione di densità è massimizzata . Applicando le definizioni generali di media e moda al modello Beta, si ottengono le seguenti formule:

$E(\pi)= \frac{\alpha}{\alpha + \beta}$

$Mode(\pi)= \frac{\alpha-1}{\alpha + \beta-2}$

Ad esempio la Media e la Moda di una $Beta(6,6)$ sono

$E(\pi)= \frac{6}{6 +6}= 0,5$

$Mode(\pi)= \frac{6-1}{6+6-2}= 0.5$

Si può anche allo stesso modo definire la Varianza:

$Var(\pi)= \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$

e la corrispondente Deviazione Standard:

$SD(\pi)= \sqrt{Var}$

# 4.3 Adattare il Prior partendo da una media

Partendo dalle formule sopra riportate, è possibile costruire una beta-priori che rifletta una convinzione (o certezza, se si dispone di dati storici) attorno a che valore abbia la media del parametro. Se pensiamo che il valore medio sia pari a 0.45, possiamo utilizzare la formula inversa per la media e calcolare $\alpha$ in funzione di $\beta$

Se la media è intorno a 0.45, allora $E(\pi)= \alpha/ (\alpha+\beta)= 0.45$, esprimibile anche così:

$\alpha\approx\frac{9}{11}\beta$

Dopodiché si tracceranno più beta che rispettino questo rapporto tra gli iperparametri, fino a trovare quella che meglio si adatta al valore medio

```{r}
library(bayesrules)
plot_beta(27,33)
```

Questa funzione è il Prior, dalla quale e possibile ricavare Media, Moda e Varianza:

$E(\pi)=\frac{27}{27+33}=0.45$

$Mode(\pi)=\frac{27-1}{27+33-2}=0.4482$

$Var(\pi)=\frac{27\cdot 33}{(27+33)^2(27+33+1)}=0.0302$

# 4.4 Tipologie di Prior

le distribuzioni a priori vengono solitamente suddivise in due macrocategorie, per quanto riguarda il grado di certezza in merito alle supposizioni fatte per la sua costruzione. Più si è certi delle informazioni inserite nel prior, minore è la variabilità della priori stesso. Una distribuzione che riflette le informazioni in merito al parametro sconosciuto con elevata certezza e quindi con bassa variabilità è definito un prior **informativo**. Una distribuzione che riflette informazioni con un basso grado di specificità e conseguentemente presenta maggiore variabilità è definita una **priori vaga**, o **diffusa**. Un caso particolare di priori vaga è la  priori"flat", che assegna uguale plausibilità a tutti valori del parametro, così come descritta dalla distribuzione uniforme già trattata. Per mostrare le caratteristiche di queste diverse priori a livello grafico, prendiamo come riferimento una vignetta satirica di *Alison Bechdel* del 1985 (@BT), "*the Rule*" dove un personaggio afferma che sarebbe disposto a guardare un film solo se presenta 3 caratteristiche: -nel film sono presenti due donne -queste donne parlano tra di loro -non parlano solamente di un uomo

Questo è il "bechdel" test per la rappresentazione delle donne nei film; a seconda di chi si trova a costruire il prior, in base alla propria opinione in merito a quanti film in percentuale superano il test, si avranno diverse curve che riflettono le proprie convinzioni.

Seguono tre esempi di  distribuzioni a Priori costruiti utilizzando la funzione Beta, ipoteticamente da 3 soggetti diversi che quindi hanno una diversa opinione sul numero di Film che supererebbe il "Bechdel" test:

```{r}
library(bayesrules)
plot_beta(1,1)
plot_beta(5,11)
plot_beta(1,17)

```

# 4.5 Bibliografia

@book{BR, title= {Bayes Rules! An Introduction to Applied Bayesian Modeling}, author= {Alicia A. Johnson, Miles Q. Ott, Mine Dogucu}, year={2021}, url={<https://www.bayesrulesbook.com/index.html>} }

@materiale{SS, title= {Probabilità e inferenza statistica} author={Luca Srucca} year={2019} }

@article{FP, title={A primer on Priors} author= {Frank Portman} year={2020} url{<https://fportman.com/writing/bayesab-0-dot-7-0-plus-a-primer-on-priors/>} }

@strip{BT, title={Dykes to Watch Out for.} autor={Alison Bechdel} year={1986} organisation={Firebrand Books} }
